{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecção de Fraudes em Cartões de Crédito.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9hz2qI42ofyfJNlAQzyn6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE8odA59a_57"
      },
      "source": [
        "![texto alternativo](https://www.moneyunder30.com/images/2016/02/securedcreditcards.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGtnimjkbEJf"
      },
      "source": [
        "---\n",
        "\n",
        "# **USO DE MACHINE LEARNING NA DETECÇÃO DE FRAUDES EM CARTÕES DE CRÉDITO**\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "Última atualização em 25 de dezembro de 2020\n",
        "\n",
        "---\n",
        "\n",
        "Diariamente, diversas operadoras de cartões de créditos captam milhares de clientes em todo o mundo, e o número de transações eletrônicas tem aumentado significativamente nos últimos anos. Para se ter uma ideia, de acordo com o Banco Central, apenas em 2017, as transações com cartões de crédito somaram cerca de R$ 674 bilhões, e o uso dessa forma de pagamento cresce a taxas substanciais ano após ano (VIEIRA, 2019).\n",
        "\n",
        "A ideia dos cartões de créditos nasceu na década de 1920 nos Estados Unidos da América, quando algumas empresas privadas, especialmente do ramo hoteleiro e do petróleo, começaram a emitir cartões para possibilitar que seus clientes comprassem a crédito nos próprios estabelecimentos. Mais tarde, em 1950, Frank MacNamara aprimorou a ideia e lançou o Diners Club, focado na aceitação em massa e menores taxas.\n",
        "\n",
        "**Tipos de Fraudes**\n",
        "\n",
        "Dentre os diversos tipos de fraudes ocorridas no mercado, as mais comuns são (OLIVEIRA, 2016):\n",
        "\n",
        "* **Invasão de Conta**: neste tipo de fraude, os criminosos obtêm informações pessoais de clientes, como número de contas e senhas, com o intuito de solicitar pagamentos, empréstimos e outros serviços bancários que estejam disponíveis;\n",
        "\n",
        "* **Roubo de identidade**: neste caso, de posse de informações pessoais, os fraudadores abrem contas novas para tirarem proveito financeiro. Basicamente, é o uso ilegal de informações de terceiros para realizar uma solicitação fraudulenta;\n",
        "\n",
        "* **Cartão perdido ou roubado**: aqui, os fraudadores tomam posse de um cartão perdido por seu verdadeiro titular, ou roubado pelo próprio fraudador, e realizam transações com ele;\n",
        "\n",
        "* **Extravio**: ocorre quando cartões e suas respectivas senhas são roubados no processo de envio do emissor do cartão para o portador/cliente;\n",
        "\n",
        "* **Falsificação de cartão**: falsificação, ou clonagem, de um cartão acontece quando um cartão é montado, sem a autorização do emissor, com os mesmos dados de um outro cartão que, por sua vez, foi emitido legitimamente.\n",
        "\n",
        "**Detecção de Fraudes**\n",
        "\n",
        "De acordo com o Serasa, apenas no ano de 2019, o Brasil sofreu uma tentativa de fraude a cada 6,5 segundos em ambientes online. E no ano de 2020, essas tentativas aumentaram devido ao crescente número de compras no comércio eletrônico durante a Pandemia da COVID-19.\n",
        "\n",
        "Para tentar contornar e evitar esses problemas, as empresas de cartões de crédito têm investido cada vez mais em tecnologias que possam detectar essas possíveis fraudes e garantir a segurança dos dados de seus clientes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBW5aUvj5Muh"
      },
      "source": [
        "## **Proposta deste Projeto**\r\n",
        "\r\n",
        "A partir de dados de operações financeiras com cartões de crédito fornecidos por diversas empresas europeias, o principal objetivo deste artigo é implementar um modelo de Machine Learning que consiga prever quais transações são ou não fraudulentas, usando aprendizado supervisionado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg4sYDyo74JT"
      },
      "source": [
        "## **Obtenção dos Dados**\r\n",
        "\r\n",
        "O dataset utilizado no presente trabalho reúne cerca de 290 mil dados de transações financeiras realizadas em um período de dois dias, fornecidos por empresas da Europa. Como é de se esperar, o número de operações fraudulentas é muito inferior em comparação às transações normais, resultando em um conjunto de dados altamente desbalanceado.\r\n",
        "\r\n",
        "Um detalhe interessante é que as features são todas numéricas, e foram descaracterizadas (por problemas relacionados à privacidade e segurança dos clientes). Assim, os nomes das colunas são representados por [V1,V2,…,V28].\r\n",
        "\r\n",
        "De acordo com a [página oficial](https://www.kaggle.com/mlg-ulb/creditcardfraud) onde os dados estão hospedados, o dataset passou por um procedimento conhecido como Análise dos Componentes Principais (*Principal Component Analysis - PCA*), cujo objetivo é obter uma simplificação do dataset através da redução da dimensão dos dados, extraindo as partes mais relevantes do conjunto de dados. No caso deste projeto, os componentes achados pela transformação da PCA são as próprias colunas [V1,V2,…,V28]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRFtYhBI7S4S"
      },
      "source": [
        "## **Análise Exploratória**\r\n",
        "\r\n",
        "Na maior parte dos projetos de Data Science, uma das primeiras etapas, e a que mais consume tempo, é a análise exploratória de dados.\r\n",
        "\r\n",
        "Esta etapa nos permite extrair as principais informações do conjunto de dados, nos auxiliando a entender o comportamento dos dados e quais os passos seguintes devem ser tomados para encontrar as soluções desejadas e também implementar os modelos de *Machine Learning*.\r\n",
        "\r\n",
        "Inicialmente, precisamos importar as principais bibliotecas que serão utilizadas ao longo da resolução do problema, que são:\r\n",
        "\r\n",
        "* Pandas;\r\n",
        "* Matplotlib;\r\n",
        "* Seaborn; e\r\n",
        "* Numpy.\r\n",
        "\r\n",
        "Caso haja a necessidade de utilizar alguma outra *lib*, como *Scikit-Learn*, será importada ademais. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLxiqwyga-6i"
      },
      "source": [
        "# IMPORTAÇÃO DAS PRINCIPAIS BIBLIOTECAS PARA ANÁLISE DE DADOS\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WLqR5tui6Nn"
      },
      "source": [
        "# IMPORTAÇÃO DO DATASET\r\n",
        "\r\n",
        "df = pd.read_csv('https://www.dropbox.com/s/b44o3t3ehmnx2b7/creditcard.csv?dl=1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "TGdBDV455n3z",
        "outputId": "048e2250-63e6-45a7-db4d-0b367f09ae1b"
      },
      "source": [
        "# VISUALIZANDO AS PRIMEIRAS LINHAS DO DATASET\r\n",
        "\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWcwf5c8--mR"
      },
      "source": [
        "A partir da visualização das primeiras cinco linhas do conjunto de dados, pode-se perceber que a variável alvo (*target*) é a coluna `Class`, que possui os valores **0** e **1**, onde representam **transação normal** e **transação fraudulenta**, respectivamente.\r\n",
        "\r\n",
        "Também é possível observar que as variáveis `Time` e `Amount` tiveram seus valores originais preservados. E que as demais variáveis V1,..,V28, tiveram suas nomenclaturas modificadas pelo método PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97aADMXtAsHl"
      },
      "source": [
        "**Agora que já sabemos a forma geral do conjunto de dados, podemos extrair alguma informações básicas.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZBYxn1b-5U2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1edf8b5-076e-464b-d02f-822d0b6d4787"
      },
      "source": [
        "# TAMANHO DO CONJUNTO DE DADOS\r\n",
        "\r\n",
        "print('Linhas: {}'.format(df.shape[0]))\r\n",
        "print('Colunas: {}'.format(df.shape[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linhas: 284807\n",
            "Colunas: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VnTcCHx8i0c"
      },
      "source": [
        "Como mostrado abaixo, verifica-se, usando o comando `.isnull`, que não há valores ausentes ou os dados que precisem de tratamento específico no *dataset*, o que representa uma boa qualidade do conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RcOfaJ2ASqL",
        "outputId": "3fcd9e03-17b8-468e-f1f1-99f22d67ef36"
      },
      "source": [
        "# VALORES AUSENTES\r\n",
        "\r\n",
        "((df.isnull().sum() / df.shape[0])*100).sort_values(ascending = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class     0.0\n",
              "V14       0.0\n",
              "V1        0.0\n",
              "V2        0.0\n",
              "V3        0.0\n",
              "V4        0.0\n",
              "V5        0.0\n",
              "V6        0.0\n",
              "V7        0.0\n",
              "V8        0.0\n",
              "V9        0.0\n",
              "V10       0.0\n",
              "V11       0.0\n",
              "V12       0.0\n",
              "V13       0.0\n",
              "V15       0.0\n",
              "Amount    0.0\n",
              "V16       0.0\n",
              "V17       0.0\n",
              "V18       0.0\n",
              "V19       0.0\n",
              "V20       0.0\n",
              "V21       0.0\n",
              "V22       0.0\n",
              "V23       0.0\n",
              "V24       0.0\n",
              "V25       0.0\n",
              "V26       0.0\n",
              "V27       0.0\n",
              "V28       0.0\n",
              "Time      0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OF0j-0UAacI"
      },
      "source": [
        "Pode-se extrair informações estatísticas básicas, seja do conjunto de dados inteiro ou de cada coluna separadamente. Por exemplo, para visualizar o resumo estatísticos de todas as variáveis juntas, usa-se a função '.describe'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "Jugm562WAXfx",
        "outputId": "cd2a25be-1411-46d7-d075-25644e341760"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>3.919560e-15</td>\n",
              "      <td>5.688174e-16</td>\n",
              "      <td>-8.769071e-15</td>\n",
              "      <td>2.782312e-15</td>\n",
              "      <td>-1.552563e-15</td>\n",
              "      <td>2.010663e-15</td>\n",
              "      <td>-1.694249e-15</td>\n",
              "      <td>-1.927028e-16</td>\n",
              "      <td>-3.137024e-15</td>\n",
              "      <td>1.768627e-15</td>\n",
              "      <td>9.170318e-16</td>\n",
              "      <td>-1.810658e-15</td>\n",
              "      <td>1.693438e-15</td>\n",
              "      <td>1.479045e-15</td>\n",
              "      <td>3.482336e-15</td>\n",
              "      <td>1.392007e-15</td>\n",
              "      <td>-7.528491e-16</td>\n",
              "      <td>4.328772e-16</td>\n",
              "      <td>9.049732e-16</td>\n",
              "      <td>5.085503e-16</td>\n",
              "      <td>1.537294e-16</td>\n",
              "      <td>7.959909e-16</td>\n",
              "      <td>5.367590e-16</td>\n",
              "      <td>4.458112e-15</td>\n",
              "      <td>1.453003e-15</td>\n",
              "      <td>1.699104e-15</td>\n",
              "      <td>-3.660161e-16</td>\n",
              "      <td>-1.206049e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>1.020713e+00</td>\n",
              "      <td>9.992014e-01</td>\n",
              "      <td>9.952742e-01</td>\n",
              "      <td>9.585956e-01</td>\n",
              "      <td>9.153160e-01</td>\n",
              "      <td>8.762529e-01</td>\n",
              "      <td>8.493371e-01</td>\n",
              "      <td>8.381762e-01</td>\n",
              "      <td>8.140405e-01</td>\n",
              "      <td>7.709250e-01</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>-4.797473e+00</td>\n",
              "      <td>-1.868371e+01</td>\n",
              "      <td>-5.791881e+00</td>\n",
              "      <td>-1.921433e+01</td>\n",
              "      <td>-4.498945e+00</td>\n",
              "      <td>-1.412985e+01</td>\n",
              "      <td>-2.516280e+01</td>\n",
              "      <td>-9.498746e+00</td>\n",
              "      <td>-7.213527e+00</td>\n",
              "      <td>-5.449772e+01</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354257e-01</td>\n",
              "      <td>-7.624942e-01</td>\n",
              "      <td>-4.055715e-01</td>\n",
              "      <td>-6.485393e-01</td>\n",
              "      <td>-4.255740e-01</td>\n",
              "      <td>-5.828843e-01</td>\n",
              "      <td>-4.680368e-01</td>\n",
              "      <td>-4.837483e-01</td>\n",
              "      <td>-4.988498e-01</td>\n",
              "      <td>-4.562989e-01</td>\n",
              "      <td>-2.117214e-01</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>-9.291738e-02</td>\n",
              "      <td>-3.275735e-02</td>\n",
              "      <td>1.400326e-01</td>\n",
              "      <td>-1.356806e-02</td>\n",
              "      <td>5.060132e-02</td>\n",
              "      <td>4.807155e-02</td>\n",
              "      <td>6.641332e-02</td>\n",
              "      <td>-6.567575e-02</td>\n",
              "      <td>-3.636312e-03</td>\n",
              "      <td>3.734823e-03</td>\n",
              "      <td>-6.248109e-02</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>4.539234e-01</td>\n",
              "      <td>7.395934e-01</td>\n",
              "      <td>6.182380e-01</td>\n",
              "      <td>6.625050e-01</td>\n",
              "      <td>4.931498e-01</td>\n",
              "      <td>6.488208e-01</td>\n",
              "      <td>5.232963e-01</td>\n",
              "      <td>3.996750e-01</td>\n",
              "      <td>5.008067e-01</td>\n",
              "      <td>4.589494e-01</td>\n",
              "      <td>1.330408e-01</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>1.201891e+01</td>\n",
              "      <td>7.848392e+00</td>\n",
              "      <td>7.126883e+00</td>\n",
              "      <td>1.052677e+01</td>\n",
              "      <td>8.877742e+00</td>\n",
              "      <td>1.731511e+01</td>\n",
              "      <td>9.253526e+00</td>\n",
              "      <td>5.041069e+00</td>\n",
              "      <td>5.591971e+00</td>\n",
              "      <td>3.942090e+01</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1  ...         Amount          Class\n",
              "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
              "mean    94813.859575  3.919560e-15  ...      88.349619       0.001727\n",
              "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
              "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
              "25%     54201.500000 -9.203734e-01  ...       5.600000       0.000000\n",
              "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
              "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
              "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfgyfPejEpaZ"
      },
      "source": [
        "Através do resumo estatístico mostrado acima, pode-se perceber que as variáveis transformadas pelo método PCA (*V1,...,V2*) não apresentam valores fora do comum, aparentemente. Isso também é verificado para a variável `Time`.\r\n",
        "\r\n",
        "Já para a variável `Amount`, referente ao valor das transações (normais e fraudes), possui uma média de 88.34, apresentando o valor máximo de 25691.16."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTXG7G-RB7bC"
      },
      "source": [
        "Em geral, o número de transações financeiras fraudulentas correspondem a uma pequena fração do total de transações. No caso do *dataset* utilizado no presente projeto, essa fração corresponde à 0,17% do total, como pode ser observado através do gráfico de barras abaixo.\r\n",
        "\r\n",
        "A princípio, esse fato pode ser prejudicial ao desempenho do modelo de *Machine Learning*, pois são classes que apresentam quantidades de dados muito discrepantes. Contudo, isso pode ser resolvido facilmente aplicando método para o balanceamento de dados, como será visto mais adiante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OAV-lAnAddX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "fdcaae1a-0736-48fd-ed55-dbc22cd1209c"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (6,4))\r\n",
        "ax = df.Class.value_counts().plot(kind = 'bar', color = 'blue')\r\n",
        "ax.set_title('Distribuição das Classes', fontsize = 15, loc ='center', weight = 'bold')\r\n",
        "ax.set_xticklabels(['Normal' , 'Fraude'], rotation = 0)\r\n",
        "ax.patch.set_facecolor('white')\r\n",
        "\r\n",
        "total = []\r\n",
        "\r\n",
        "for i in ax.patches:\r\n",
        "    total.append(i.get_height())\r\n",
        "\r\n",
        "soma = sum(total)\r\n",
        "\r\n",
        "for i in ax.patches:\r\n",
        "    ax.text(i.get_x() + .12, i.get_height() - 50,\r\n",
        "            str(round((i.get_height()/soma)*100, 2)) + '%',\r\n",
        "            fontsize = 12, color = 'black', weight = 'bold')\r\n",
        "    \r\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag78qZJtC2un",
        "outputId": "9c38b8ca-b94c-44a3-b5f2-a8cfef26b69c"
      },
      "source": [
        "# QUANTIDADE DE DADOS EM CADA CLASSE\r\n",
        "\r\n",
        "print('Normais: ', df[df.Class == 0].shape[0])\r\n",
        "print('\\nFraudes: ', df[df.Class == 1].shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normais:  284315\n",
            "\n",
            "Fraudes:  492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPlh97xASwi3"
      },
      "source": [
        "O próximo passo da análise exploratória foi verificar se existem *outliers* nos dados, levando em consideração o parão dos dados referentes às transações financeiras em relação à variável `Amount`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "MVf2SJBoN7oi",
        "outputId": "393b9276-6213-4c72-a9e3-fe7a220ad459"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (5,8), sharex = True)\r\n",
        "\r\n",
        "sns.boxplot(df.Class, df.Amount, showmeans = True, ax = ax)\r\n",
        "plt.ylim((-20, 400))\r\n",
        "plt.xticks([0, 1], ['Normal', 'Fraude'])\r\n",
        "\r\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outVnoUNXSL8"
      },
      "source": [
        "Como pode-se perceber, as distribuições são diferentes para cada classe observada, o que pode ser um aspecto positivo para o treinamento e teste do modelo de *Machine Learning*.\r\n",
        "\r\n",
        "De fato, existem *outliers* na variável `Amount`, o que pode ser tratado com a padronização dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp3aVFnR1tSb"
      },
      "source": [
        "## **Preparação dos Dados**\r\n",
        "\r\n",
        "Após realizar a análise exploratória e extrair as principais informações do conjunto de dados, a próxima etapa é fazer a preparação e o tratamento das variáveis que irão alimentar o modelo de *Machine Learning*. O modelo preditivo a ser implementado será de Aprendizado Supervisionado.\r\n",
        "\r\n",
        "\r\n",
        "Nesta etapa, deve-se fazer os ajustes finais dos dados. Esses ajustes envolvem a padronização das *features*, criação de novas variáveis, limpeza dos dados, separação do dataset, etc.\r\n",
        "\r\n",
        "Para alimentar o modelo de Machine Learning, é necessário separar a variável alvo (dependente) das demais variáveis (independentes).\r\n",
        "\r\n",
        "Por padrão, é comum fazer a divisão do conjunto de dados em variáveis nomeadas como X e y. Este projeto seguiu a mesma ideia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-uL_Whf5KKK"
      },
      "source": [
        "### **Padronização dos Dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_bGZVPH2uj8"
      },
      "source": [
        "**A variável `Amount` receberá uma atenção especial nesta etapa, uma vez que ela apresenta *outliers*. Assim, é fundamental realizar a padronização dessa variável. O mesmo processo será realizado para a coluna `Time`, por ela possuir valores numéricos diferentes dos padrões das demais variáveis. Para isso, pode-se utilizar o método *StandardScaler*.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j3oxjtsqkoW"
      },
      "source": [
        "# IMPORTAÇÃO DAS FERRAMENTAS PARA O PRÉ-PROCESSAMENTO DOS DADOS\r\n",
        "\r\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GWIwyn93yho"
      },
      "source": [
        "# CRIANDO UMA CÓPIA DO DATASET ORIGINAL\r\n",
        "\r\n",
        "df_pdz = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KdWZNMI3uWx"
      },
      "source": [
        "# PADRONIZAÇÃO DAS VARIÁVEIS AMOUNT E TIME\r\n",
        "\r\n",
        "pdz = StandardScaler()\r\n",
        "\r\n",
        "df_pdz['amount_pdz'] = pdz.fit_transform(df_pdz['Amount'].values.reshape(-1, 1))\r\n",
        "df_pdz['time_pdz'] = pdz.fit_transform(df_pdz['Time'].values.reshape(-1, 1))\r\n",
        "\r\n",
        "# ELIMINANDO AS VARIÁVEIS ANTIGAS\r\n",
        "\r\n",
        "df_pdz.drop(['Time', 'Amount'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "4NztzJTY4JBP",
        "outputId": "f86c660b-d412-4e96-becc-ba9370c87ef3"
      },
      "source": [
        "# VISUALIZANDO O RESULTADO\r\n",
        "\r\n",
        "df_pdz.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "      <th>amount_pdz</th>\n",
              "      <th>time_pdz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0</td>\n",
              "      <td>0.244964</td>\n",
              "      <td>-1.996583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.342475</td>\n",
              "      <td>-1.996583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>0</td>\n",
              "      <td>1.160686</td>\n",
              "      <td>-1.996562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0</td>\n",
              "      <td>0.140534</td>\n",
              "      <td>-1.996562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.073403</td>\n",
              "      <td>-1.996541</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1        V2        V3  ...  Class  amount_pdz  time_pdz\n",
              "0 -1.359807 -0.072781  2.536347  ...      0    0.244964 -1.996583\n",
              "1  1.191857  0.266151  0.166480  ...      0   -0.342475 -1.996583\n",
              "2 -1.358354 -1.340163  1.773209  ...      0    1.160686 -1.996562\n",
              "3 -0.966272 -0.185226  1.792993  ...      0    0.140534 -1.996562\n",
              "4 -1.158233  0.877737  1.548718  ...      0   -0.073403 -1.996541\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ird6I1z5oYT"
      },
      "source": [
        "### **Divisão dos Dados em Treino e Teste**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ali3MvDF5Bjv"
      },
      "source": [
        "# SEPARAÇÃO DAS VARIÁVEIS EM DEPENDENTE E INDEPENDENTE\r\n",
        "\r\n",
        "X = df_pdz.drop(['Class'], axis = 1)\r\n",
        "y = df_pdz.Class\r\n",
        "\r\n",
        "# DIVISÃO DOS DADOS EM TREINO E TESTE\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.28, stratify = y, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C1AuoVH6rLN"
      },
      "source": [
        "Neste ponto, após a divisão dos dados, pode-se implementar o modelo com os dados desbalanceados. A ideia é comparar o desempenho do método frente às duas situações: dados desbalanceados e balanceados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEHwRoat8zHn"
      },
      "source": [
        "**MODELO COM OS DADOS DESBALANCEADOS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "AOibrF6m880f",
        "outputId": "48cd0650-c1ce-4e23-ddfa-7ac355855027"
      },
      "source": [
        "# VISUALIZANDO AS CLASSES DA VARIÁVEL ALVO\r\n",
        "\r\n",
        "sns.countplot(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc811f0e208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kheQiRhk6qvR"
      },
      "source": [
        "# MODELO RANDOM FOREST PARA CLASSIFICAÇÃO\r\n",
        "\r\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E9uOj978bn5"
      },
      "source": [
        "# INSTANCIANDO O MODELO\r\n",
        "\r\n",
        "rfc_model = RandomForestClassifier(criterion = 'entropy', random_state = 42, oob_score = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBFAtR4j8lDr",
        "outputId": "a9464358-6331-4d4c-9f7e-5b0d58b791b5"
      },
      "source": [
        "# TREINANDO O MODELO\r\n",
        "\r\n",
        "rfc_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=True, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yuFpKlD9qv4"
      },
      "source": [
        "# REALIZANDO A PREVISÃO NOS DADOS DE TESTE\r\n",
        "\r\n",
        "y_pred = rfc_model.predict(X_test)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVbf45KzDtZY"
      },
      "source": [
        "# IMPORTANDO MÉTRICAS DE AVALIAÇÃO\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKKTSMErD3Pl",
        "outputId": "5164eb25-baae-49b0-fdc5-ba9103c506fe"
      },
      "source": [
        "print('Random Forest')\r\n",
        "\r\n",
        "# ACURÁCIA\r\n",
        "\r\n",
        "print('\\n[Acurácia]:', accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "# OOB DO RANDOM FOREST\r\n",
        "\r\n",
        "print('\\n[Out-of-Bag]:', rfc_model.oob_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest\n",
            "\n",
            "[Acurácia]: 0.9995485666992702\n",
            "\n",
            "[Out-of-Bag]: 0.9995415998166399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OpU8R2pEDJj",
        "outputId": "4961b362-c34a-4d77-ba20-7be0745aff5a"
      },
      "source": [
        "# VISUALIZANDO O CLASSIFICATION REPORT\r\n",
        "\r\n",
        "print('\\n[Classification Report] Random Forest')\r\n",
        "\r\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Classification Report] Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     79608\n",
            "           1       0.97      0.76      0.85       138\n",
            "\n",
            "    accuracy                           1.00     79746\n",
            "   macro avg       0.99      0.88      0.93     79746\n",
            "weighted avg       1.00      1.00      1.00     79746\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "aZa-W0M5EMWX",
        "outputId": "3d40ccf8-371a-4c1e-e651-ecfebff39378"
      },
      "source": [
        "# VISUALIZANDO A MATRIZ DE CONFUSÃO\r\n",
        "\r\n",
        "pd.DataFrame(confusion_matrix(y_test, y_pred),\r\n",
        "             index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_neg</th>\n",
              "      <th>pred_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neg</th>\n",
              "      <td>79605</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pos</th>\n",
              "      <td>33</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     pred_neg  pred_pos\n",
              "neg     79605         3\n",
              "pos        33       105"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t27i6SMAOIR"
      },
      "source": [
        "Pode-se observar acima que mesmo o utilizando os dados desbalanceados, a acurácia está em quase 100%. É importante enfatizar que isso não significa que o modelo está tendo um bom desempenho necessariamente, pois além da acurácia não ser a forma definitiva de avaliar os modelos, pode estar ocorrendo alguns problemas. Na verdade, é provável que essa acurácia seja resultado de o modelo ter sido enviesado.\r\n",
        "\r\n",
        "Para tentar contornar o problema, pode-se fazer o balanceamento dos dados e fazer o treino e teste do modelo novamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxwmn39xBS9j"
      },
      "source": [
        "### **Balanceamento dos Dados**\r\n",
        "\r\n",
        "Quando se trata de balanceamento de dados, pode-se aplicar duas abordagens: *Undersampling* e *Oversampling*.\r\n",
        "\r\n",
        "No primeiro caso, a técnica consiste em reduzir os exemplos da classe majoritária de forma aleatória. Já o segundo, faz réplicas dos dados da classe minoritária.\r\n",
        "\r\n",
        "No presente projeto, aplicacou-se a técnica de Undersampling, usando algoritmo NearMiss para esta finalidade."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOTZMMemA_BJ"
      },
      "source": [
        "# IMPORTAÇÃO DO NEARMISS A PARTIR DA BIBLIOTECA IMBLEARN\r\n",
        "\r\n",
        "from imblearn.under_sampling import NearMiss\r\n",
        "\r\n",
        "# INSTANCIANDO O ALGORITMO\r\n",
        "\r\n",
        "NM = NearMiss()\r\n",
        "\r\n",
        "# APLICANDO O UNDERSAMPLING\r\n",
        "\r\n",
        "X_US, y_US = NM.fit_sample(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMmJW3u7KTdf",
        "outputId": "22c10bb4-6e07-4fd5-cd00-068f1ca6f42e"
      },
      "source": [
        "print(pd.Series(y_US).value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    492\n",
            "0    492\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "t9Xs22xcFo1z",
        "outputId": "a97f08aa-fe0f-4e60-82d5-8f2e6f114d59"
      },
      "source": [
        "# VISUALIZANDO AS CLASSES DA VARIÁVEL ALVO BALANCEADA\r\n",
        "\r\n",
        "sns.countplot(y_US)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc8149602b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7157KIOF4Gx"
      },
      "source": [
        "Como pode-se observar acima, de fato, o método aplicado foi capaz de balancear as classes da variável independente. Com isso, o modelo de *Machine Learning* pode ser treinado e testado novamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRceKtPrGbdm"
      },
      "source": [
        "**MODELO COM OS DADOS BALANCEADOS**\r\n",
        "\r\n",
        "Como as bibliotecas já foram importadas anteriormente, pode-se aplicar o modelo de forma mais direta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rFOc8W-JpcY"
      },
      "source": [
        "# SEPARANDO NOVAMENTE OS DADOS DE TREINO E TESTE\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_US, y_US, test_size = 0.28, stratify = y_US, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "874-CF85F3Kt",
        "outputId": "0e197f3e-d667-488d-c375-8715495fe86f"
      },
      "source": [
        "# TREINANDO O MODELO\r\n",
        "\r\n",
        "rfc_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=True, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poJueiVtH-YB"
      },
      "source": [
        "# PREVISÃO\r\n",
        "\r\n",
        "y_pred = rfc_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdOqUwsyGv1q",
        "outputId": "b517eeb9-b1dc-4003-d8f9-73590cc404a3"
      },
      "source": [
        "print('Random Forest')\r\n",
        "\r\n",
        "# ACURÁCIA\r\n",
        "\r\n",
        "print('\\n[Acurácia]:', accuracy_score(y_test, y_pred))\r\n",
        "\r\n",
        "# OOB DO RANDOM FOREST\r\n",
        "\r\n",
        "print('\\n[Out-of-Bag]:', rfc_model.oob_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest\n",
            "\n",
            "[Acurácia]: 0.9818840579710145\n",
            "\n",
            "[Out-of-Bag]: 0.9646892655367232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GZ3VzI1H5xg",
        "outputId": "8e6cd1d1-7d4d-4665-b818-83e626c3dfa0"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       138\n",
            "           1       0.99      0.98      0.98       138\n",
            "\n",
            "    accuracy                           0.98       276\n",
            "   macro avg       0.98      0.98      0.98       276\n",
            "weighted avg       0.98      0.98      0.98       276\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "Rxh7_OxqI4pB",
        "outputId": "f084fc66-3a8f-42af-b3c6-776d7c810f50"
      },
      "source": [
        "# VISUALIZANDO A MATRIZ DE CONFUSÃO\r\n",
        "\r\n",
        "pd.DataFrame(confusion_matrix(y_test, y_pred),\r\n",
        "             index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_neg</th>\n",
              "      <th>pred_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neg</th>\n",
              "      <td>136</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pos</th>\n",
              "      <td>3</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     pred_neg  pred_pos\n",
              "neg       136         2\n",
              "pos         3       135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu8LJslrLDpq"
      },
      "source": [
        "## **Conclusão**\r\n",
        "\r\n",
        "Como pode-se observar nos resultados, ao comparar as duas situações, o modelo obteve uma acurácia maior com os dados desbalanceados. Contudo, outras métricas importantes como **recall** e **f1-score** foram bem melhores quando o modelo foi alimentado com os dados balanceados. Em resumo:\r\n",
        "\r\n",
        "* **Precision** — Precisão de previsões positivas\r\n",
        "* **Recall** — Fração de positivos que foram identificados corretamente.\r\n",
        "* **f1-score** — representa a média harmônica entre precision e recall, sendo 0 o pior valor e 1 o melhor.\r\n",
        "\r\n",
        "Assim, o modelo com os dados balanceados foi capaz de identificar de maneira mais precisas as transações que, de fato, eram fraudulentas, um aspecto muito importante para este projeto, afinal, o objetivo é justamente conseguir identificar as fraudes.\r\n",
        "\r\n",
        "Como discutido anteriormente, o modelo realmente pode ter sido enviesado pela classe majoritária com os dados desbalanceados e, foi possível contornar isso usando técnicas apropriadas.\r\n",
        "\r\n",
        "O modelo final alcançou uma **acurácia de 98,19%**, combinado aos bons resultados das demais métricas. Em particular, para o Random Forest, o parâmetro [***Out-of-Bag***](https://towardsdatascience.com/what-is-out-of-bag-oob-score-in-random-forest-a7fa23d710) é bastante relevante, e o modelo também apresentou um bom resultado para essa métrica, atingindo **96,46%**.\r\n",
        "\r\n",
        "No geral, o modelo alcançou um ótimo desempenho, mas é importante ressaltar que existem outras técnicas para procurar melhorar esse resultado, seja por meio da implementação de outros modelo de classificação ou o ajuste de hiperparâmetros do modelo atual, por exemplo. "
      ]
    }
  ]
}
